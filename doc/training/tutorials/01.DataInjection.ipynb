{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Injection on Monit\n",
    "In this tutorial, we will prepare a dataset and sent it to the MonIT infrastructure. We will use Spark to check at the data once it is ingested in HDFS. \n",
    "\n",
    "## Requirements\n",
    "\n",
    "  - A swan environment:\n",
    "      - If you haven't used swan or cernbox before login first in cernbox to have you eos folder created.\n",
    "      - go to https://swan.cern.ch, login and create a new session with the following configuration:\n",
    "            Software stack 96 Python 3\n",
    "            Platform CentOS 7 (gcc8)\n",
    "            Number of cores 4\n",
    "            Memory 8 GB\n",
    "            Spark cluster Analytix[+]\n",
    "  - This notebook\n",
    "        In SWAN, create a new project (using the + button). Enter to the project folder.\n",
    "        Download this notebook and import it to the new project using the upload file button.\n",
    "        \n",
    "[+] Optional, if you want to see your data in HDFS you will need to have access to the Analytix cluster. If you haven't used HDFS at CERN before, you will need to create a [SNOW ticket to the Hadoop service element](https://hadoop-user-guide.web.cern.ch/hadoop-user-guide/getstart/access.html) to have your account authorized. Please specify that you will use the Analytix cluster to access CMS data.  **This will be required to run the Spark part of this tutorial.**\n",
    "\n",
    "### Before start\n",
    "\n",
    "To inject data into MonIT we will use the StompAMQ module of the CMSMonitoring package. You can install it using pip:\n",
    "\n",
    "```\n",
    "pip install CMSMonitoring\n",
    "```\n",
    "In case of swan you will need to install it in the user space, you can do it running the next cell\n",
    "\n",
    "**Note** As a best practice you *should* use a virtual environment for your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: CMSMonitoring==0.3.3 in /eos/home-c/carizapo/.local/lib/python3.6/site-packages (0.3.3)\n",
      "Requirement already satisfied: genson>=1.0.2 in /eos/home-c/carizapo/.local/lib/python3.6/site-packages (from CMSMonitoring==0.3.3) (1.1.0)\n",
      "Collecting stomp.py==4.1.21 (from CMSMonitoring==0.3.3)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages (from CMSMonitoring==0.3.3) (3.0.1)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /eos/home-c/carizapo/.local/lib/python3.6/site-packages (from stomp.py==4.1.21->CMSMonitoring==0.3.3) (0.6.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages (from jsonschema>=2.6.0->CMSMonitoring==0.3.3) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages (from jsonschema>=2.6.0->CMSMonitoring==0.3.3) (0.15.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/swan (from jsonschema>=2.6.0->CMSMonitoring==0.3.3) (41.6.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/swan (from jsonschema>=2.6.0->CMSMonitoring==0.3.3) (1.13.0)\n",
      "Installing collected packages: stomp.py\n",
      "\u001b[33m  WARNING: The script stomp is installed in '/eos/user/c/carizapo/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed stomp.py-4.1.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "['/eos/user/c/carizapo/.local/lib/python3.6/site-packages', '/cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib', '/tmp/spark-ba059d9a-9102-42e3-b311-74217ed80409/userFiles-4102d8d5-48f5-4369-aec6-b6b3874159ef', '', '/cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages', '/cvmfs/sft.cern.ch/lcg/releases/Python/3.6.5-f74f0/x86_64-centos7-gcc8-opt/lib/python36.zip', '/cvmfs/sft.cern.ch/lcg/releases/Python/3.6.5-f74f0/x86_64-centos7-gcc8-opt/lib/python3.6', '/cvmfs/sft.cern.ch/lcg/releases/Python/3.6.5-f74f0/x86_64-centos7-gcc8-opt/lib/python3.6/lib-dynload', '/eos/user/c/carizapo/.local/lib/python3.6/site-packages', '/cvmfs/sft.cern.ch/lcg/releases/Python/3.6.5-f74f0/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages', '/usr/local/lib/swan/IPython/extensions', '/scratch/carizapo/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# The jupyter magic command will install the package (this notebook was produced with the version 0.3.3)\n",
    "%pip install --user CMSMonitoring==0.3.3\n",
    "# As the package is installed in the user space we will need to update the sys.path list \n",
    "# to use it. This is only necessary if you don't want to restart the kernel.\n",
    "# (i.e. you will not need to do this in a script.)\n",
    "import sys\n",
    "import site\n",
    "sys.path.insert(0,site.getusersitepackages())\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start\n",
    "\n",
    "### What are we doing when we send data to monit? \n",
    "\n",
    "In the monit infrastructure we have different ways to send data, the most common one is to use the AMQ enpoint. \n",
    "\n",
    "producer --> AMQ endpoint --> flume --> Kafka --> flume --> [HDFS/INFLUXDB/ElasticSearch] --> [Kibana/Grafana/Swan...]\n",
    "\n",
    "In this tutorial we are creating a new producer. \n",
    "\n",
    "\n",
    "In order to send data to AMQ the producer should known the broker, his credentials and the topic where it will store the messages. \n",
    "\n",
    "**In this tutorial we will use the training topic and the training user credentials**. When developing your own producer, you should obtain a proper end-point from CERN MONIT team. You can arrange this by opening either a CMSMONIT Jira ticket or a SNOW ticket. The former will be directed to CMS Monitoring group and we'll coordinate its progress with CERN MONIT team, the later will go directly to CERN MONIT line of support and bypass CMS Monitoring. Please choose accordingly. In the ticket you should specify the following mandatory items:\n",
    "\n",
    "  - The data volume you foresee from your data-provider to CERN MONIT, an approximate numbers are sufficient, e.g. size of JSON document times number of docs per certain time\n",
    "  - An approximate injection rate, e.g. 1K docs per day\n",
    "  - You should provide desired topic name where your docs will appear, e.g. cms-my-topic (try always to use the cms prefix followed by your topic name)\n",
    "  - Your preference for authentication, password based or X509 certificate\n",
    "  - Provide an e-group which will be used for communication between your team and CERN MONIT\n",
    "\n",
    "Once you have the appropiated credentials you need to: \n",
    "\n",
    "   - Collect your data\n",
    "   - Transform your data into the required format\n",
    "   - Send the messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will install the dependecies, we will use StompAMQ from CMSMonitoring and also the json package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from itertools import islice\n",
    "from CMSMonitoring.StompAMQ import StompAMQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_from_mock_file(samples=100, username=None, location=\"/eos/user/c/cmsmonit/training/trainingCMSData.json\"):\n",
    "    \"\"\"\n",
    "    Get training data from a text file, add to it the timestamp and the username\n",
    "    and yield it as a dictionary.\n",
    "    ```\n",
    "    {\n",
    "        'id': 1,\n",
    "        'country': 'BR',\n",
    "        'tier': 'T0',\n",
    "        'siteName': 'T0_BR_vermin',\n",
    "        'requestedCores': 3.39,\n",
    "        'requestedMB': 1054,\n",
    "        'usedMB': 1156,\n",
    "        'training_username': 'training',\n",
    "        'timestamp': 1583770104.5563471\n",
    "    }\n",
    "    ```\n",
    "    \n",
    "    If samples is bigger than the actual data it will read again from the start.\n",
    "    The data was gerenated using mockaroo with the template\n",
    "    https://mockaroo.com/b01a5310\n",
    "    \"\"\"\n",
    "    if not username:\n",
    "        username = os.getenv(\"USER\")\n",
    "    with open(location,\"r\") as mock_data_file:\n",
    "        for i in range(0,samples):\n",
    "            json_line =  mock_data_file.readline()\n",
    "            if not json_line:\n",
    "                mock_data_file.seek(0)\n",
    "                json_line =  mock_data_file.readline()\n",
    "            data = json.loads(json_line)\n",
    "            data[\"training_username\"] = username\n",
    "            data[\"timestamp\"] = time.time()\n",
    "            yield data\n",
    "            \n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and send your data\n",
    "\n",
    "The StompAMQ module provides you with methods to tranform and send your data in the appropiate format. \n",
    "It will requires that you:\n",
    "  - create a `StompAMQ` instance that will act as your connection to the AMQ broker. \n",
    "  - transform your documents using the `make_notification` method\n",
    "  - send it using the `send`\n",
    "  \n",
    "In order to create the StompAMQ instance you will need the producer name, the topic, the host and port of the broker, and the credentials to autenticate. The credentials can be either certificates or username-password pairs. When you are ussing certificates you need to use an empty username and password. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"\"\n",
    "password = \"\"\n",
    "producer = \"cms-training\"\n",
    "topic = \"/topic/cms.training\"\n",
    "host = \"cms-test-mb.cern.ch\"\n",
    "port = 61323\n",
    "cert = \"/eos/user/c/cmsmonit/training/.globus/robot-training-cert.pem\"\n",
    "ckey = \"/eos/user/c/cmsmonit/training/.globus/robot-training-key.pem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tip*: In a notebook you can explore the singature and documentation of any method or class using an `?` after it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "StompAMQ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:StompAMQ:No document validation performed!\n"
     ]
    }
   ],
   "source": [
    "stomp_amq = StompAMQ(username, password, producer, topic, key=ckey, cert=cert, validation_schema=None, host_and_ports=[(host, port)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stomp_amq.make_notification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we will send 1000 messages, in batches of 100 each 10 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_messages = 1000\n",
    "wait_seconds = 10\n",
    "gen_data = get_training_data_from_mock_file(n_messages)\n",
    "\n",
    "eod = False\n",
    "while not eod: \n",
    "    messages = []\n",
    "    for d in take(batch_size, gen_data):\n",
    "        notif,_,_ = stomp_amq.make_notification(d, \"training_document\", dataSubfield=None, ts=d[\"timestamp\"])\n",
    "        messages.append(notif)\n",
    "    if messages:\n",
    "        stomp_amq.send(messages)\n",
    "        time.sleep(wait_seconds)\n",
    "    else:\n",
    "        eod = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the messages have been send to the AMQ queue. It will take some seconds to make them available both on ES and HDFS. \n",
    "\n",
    "On Kibana we can see the data at  https://monit-kibana.cern.ch/kibana/goto/078e54ae56b3b354ad3328d5e8053a7d\n",
    "\n",
    "On Grafana you can see the elastic search data using the monit_prod_cms-training datasource, as [you can see in this dashboard](https://monit-grafana.cern.ch/d/_S0CjmuWk/user-carizapo-training_test?orgId=11). \n",
    "\n",
    "On HDFS Monit Data is available at `/project/monitoring/archive/<<producer>>/<<prefix>>/<<doc_type>>/<<date yyy/MM/dd>>`, e.g. `/project/monitoring/archive/cms-training/raw/metric/2020/03`. \n",
    "**Note**: The current day data in hadoop is not compacted yet, so the day folder will end in `.tmp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 items\n",
      "-rw-r--r--+  3 monitops hdfs     139717 2020-03-10 11:41 /project/monitoring/archive/cms-training/raw/metric/2020/03/10.tmp/FlumeData.monit-hdfssink-5cf2740dc3.1583833266033\n",
      "-rw-r--r--+  3 monitops hdfs      13251 2020-03-10 14:20 /project/monitoring/archive/cms-training/raw/metric/2020/03/10.tmp/FlumeData.monit-hdfssink-5cf2740dc3.1583846449466.tmp\n",
      "-rw-r--r--+  3 monitops hdfs     140727 2020-03-10 11:41 /project/monitoring/archive/cms-training/raw/metric/2020/03/10.tmp/FlumeData.monit-hdfssink-79c09cf15c.1583833269017\n",
      "-rw-r--r--+  3 monitops hdfs      12219 2020-03-10 14:20 /project/monitoring/archive/cms-training/raw/metric/2020/03/10.tmp/FlumeData.monit-hdfssink-79c09cf15c.1583846447185.tmp\n",
      "-rw-r--r--+  3 monitops hdfs     139497 2020-03-10 11:41 /project/monitoring/archive/cms-training/raw/metric/2020/03/10.tmp/FlumeData.monit-hdfssink-81f7c441d4.1583833269691\n",
      "-rw-r--r--+  3 monitops hdfs      17359 2020-03-10 14:20 /project/monitoring/archive/cms-training/raw/metric/2020/03/10.tmp/FlumeData.monit-hdfssink-81f7c441d4.1583846449622.tmp\n",
      "-rw-r--r--+  3 monitops hdfs     141505 2020-03-10 11:41 /project/monitoring/archive/cms-training/raw/metric/2020/03/10.tmp/FlumeData.monit-hdfssink-8fa40dd995.1583833273683\n",
      "-rw-r--r--+  3 monitops hdfs       3572 2020-03-10 14:20 /project/monitoring/archive/cms-training/raw/metric/2020/03/10.tmp/FlumeData.monit-hdfssink-8fa40dd995.1583846443537.tmp\n",
      "{\"metadata\":{\"hostname\":\"monit-amqsource-42bd3643dc.cern.ch\",\"partition\":\"9\",\"type_prefix\":\"raw\",\"kafka_timestamp\":1583833262584,\"topic\":\"cms-training_raw_metric\",\"producer\":\"cms-training\",\"_id\":\"3c8955e8-8dad-41d1-a68f-3552056ecdb9\",\"type\":\"metric\",\"version\":\"001\",\"timestamp\":1583833261994},\"data\":{\"id\":3,\"country\":\"ID\",\"tier\":\"T3\",\"siteName\":\"T3_ID_afternoon\",\"requestedCores\":4.23,\"requestedMB\":501,\"usedMB\":3102,\"training_username\":\"carizapo\",\"metadata\":{\"uuid\":\"3c8955e8-8dad-41d1-a68f-3552056ecdb9\"}}}\n"
     ]
    }
   ],
   "source": [
    "#In order to make this work you need access to the analytix cluster. \n",
    "!hadoop fs -ls \"/project/monitoring/archive/cms-training/raw/metric/$(date +'%Y/%m/%d').tmp\" 2>/dev/null\n",
    "!hadoop fs -cat \"/project/monitoring/archive/cms-training/raw/metric/$(date +'%Y/%m/%d').tmp/*\" 2>/dev/null |head -n1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the hdfs data from spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** You only can run this part of the tutorial if you created the Swan environment connected to the Analytix cluster.  \n",
    "### Introduction to Spark on Swan\n",
    "Swan will take care of the creation of the spark session/spark context variables. In order to do so you need to start the spark session using the star icon.\n",
    "![]( data:image/png;base64,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)\n",
    "For this notebook you can start the session using the default configuration. \n",
    "Before clicking connect take some time to explore this interface, some useful variables you could set here are:\n",
    "  - spark.executor.memory\n",
    "  - spark.driver.memory\n",
    "  - spark.executor.instances\n",
    "  - spark.executor.cores\n",
    "  - spark.sql.shuffle.partitions\n",
    "  \n",
    "Once you are connected to the spark session two variables are created for you:\n",
    "    - `spark`: The spark session\n",
    "    - `sc`: The spark context\n",
    "Run the next cell to see more information about them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://swan005.cern.ch:5266\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark_shell_swan</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f938e352908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://swan005.cern.ch:5266\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark_shell_swan</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark_shell_swan>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark)\n",
    "display(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as you are now connected to a hadoop cluster, you can use the Hadoop (elephant) icon to browse the data in HDFS. Use it to see the available data in `/project/monitoring/archive/cms-training/raw/metric/`\n",
    "![](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" id="svg20" preserveAspectRatio="xMidYMid meet" viewBox="0 0 81.000008 61.220618" height="45.348606" width="60.000008" version="1.0">
  <defs id="defs24"/>
  <g style="fill:#000000;stroke:none" id="g18" transform="matrix(0.01202191,0,0,-0.01202191,-1.0847093,61.521167)">
    <path id="path4" d="m 3342,5094 c -171,-50 -259,-116 -324,-241 -38,-72 -94,-231 -85,-240 3,-3 18,19 33,49 46,90 94,160 158,226 77,81 131,120 248,182 103,55 95,61 -30,24 z"/>
    <path id="path6" d="m 4140,5093 c -168,-27 -356,-83 -537,-159 -182,-76 -289,-150 -424,-291 -47,-49 -105,-117 -129,-151 -36,-50 -52,-63 -80,-68 -126,-22 -195,-64 -355,-217 l -126,-119 -149,-28 C 1860,3970 1586,3853 1305,3618 1155,3494 1046,3366 957,3215 882,3088 777,2983 686,2945 l -38,-16 20,28 c 24,35 43,91 51,155 l 6,49 44,-61 c 24,-33 46,-58 49,-56 13,13 32,130 32,199 0,82 -16,135 -50,172 -19,21 -19,22 12,103 17,45 29,84 27,87 -12,11 -124,-26 -193,-63 -153,-83 -271,-194 -329,-312 -52,-106 -43,-222 24,-295 10,-11 28,-52 40,-90 30,-99 63,-158 106,-194 47,-39 131,-65 193,-59 l 46,5 -9,-66 c -11,-83 -3,-457 13,-534 11,-55 10,-62 -26,-160 L 667,1735 519,1584 C 372,1436 370,1433 370,1389 371,1217 476,1011 630,882 764,769 892,709 1008,702 c 39,-2 72,-6 72,-8 0,-2 -16,-42 -35,-88 -64,-155 -43,-248 72,-320 66,-41 150,-70 372,-126 186,-48 302,-64 396,-57 178,13 239,89 252,312 6,110 17,139 98,263 52,82 66,133 58,221 -6,58 -4,64 11,58 9,-4 84,-10 165,-13 l 149,-7 -31,-21 c -87,-59 -105,-159 -54,-302 53,-146 237,-418 345,-508 78,-65 124,-81 228,-81 86,0 95,2 175,42 94,47 113,63 163,147 27,45 66,84 173,171 134,109 139,113 164,99 49,-25 154,-34 405,-34 283,0 328,7 381,62 45,46 63,97 70,192 5,72 3,88 -20,141 -23,55 -25,76 -30,250 -6,216 -4,211 -107,471 -37,96 -66,174 -63,174 2,0 61,-52 130,-115 162,-148 218,-178 349,-183 144,-7 263,37 378,139 69,61 117,140 150,248 l 29,93 41,-6 c 22,-3 95,-9 161,-12 210,-12 408,23 564,97 309,146 510,440 586,856 23,123 30,392 15,554 -22,242 -69,462 -135,635 -43,111 -70,148 -141,196 -65,44 -109,58 -182,58 -86,0 -113,-20 -218,-169 -58,-82 -110,-128 -179,-156 l -34,-15 -41,78 c -46,88 -121,191 -187,257 -25,25 -105,86 -178,135 -73,50 -206,153 -296,231 -261,224 -369,298 -533,365 -131,53 -245,74 -401,73 -71,-1 -141,-4 -155,-6 z m 420,-162 c 164,-48 311,-138 528,-324 67,-58 149,-127 183,-153 64,-51 64,-55 -6,-70 -37,-7 -35,-8 44,-16 66,-6 96,-15 140,-40 96,-53 158,-105 204,-170 61,-87 141,-227 134,-235 -4,-3 -26,2 -50,11 -61,23 -99,20 -175,-13 -37,-16 -87,-35 -112,-43 l -45,-13 51,-3 50,-3 -3,-62 c -4,-60 -3,-61 11,-31 14,32 33,44 67,44 26,0 59,-35 59,-64 0,-21 -9,-27 -72,-48 l -73,-23 137,-3 c 151,-3 140,2 154,-74 7,-44 -6,-49 -58,-22 -23,12 -47,15 -87,11 -139,-14 -223,-66 -259,-160 -60,-160 -71,-191 -69,-194 2,-1 30,45 63,104 67,120 103,154 193,179 31,9 64,18 74,21 10,2 -4,-17 -30,-44 -58,-57 -69,-90 -88,-251 -7,-65 -17,-130 -20,-145 -4,-15 -5,-27 -1,-27 3,0 24,60 47,133 23,72 50,148 59,167 35,69 113,130 167,130 h 31 l 7,-86 c 8,-94 2,-193 -20,-319 -29,-166 -28,-153 -11,-125 24,39 53,135 82,265 29,137 34,267 14,412 -19,141 -6,160 150,218 86,33 128,68 231,195 40,50 83,93 98,98 61,21 136,-30 180,-121 85,-178 151,-551 151,-854 0,-249 -41,-438 -140,-638 -125,-254 -295,-405 -540,-475 -108,-32 -327,-38 -475,-15 -215,33 -524,128 -639,195 -38,22 -70,39 -72,37 -2,-1 1,-32 6,-67 11,-74 7,-109 -26,-239 -32,-125 -32,-225 -1,-272 46,-70 158,-93 247,-52 l 45,21 -52,-5 c -75,-8 -138,4 -173,33 -42,36 -37,46 13,28 61,-23 162,-23 219,-1 56,22 103,72 117,124 6,21 17,63 26,94 l 15,56 40,-10 c 22,-6 40,-16 40,-22 0,-33 -64,-207 -89,-241 -91,-126 -276,-194 -408,-150 -68,23 -113,55 -276,198 -137,121 -147,128 -243,163 -124,47 -177,73 -283,142 l -84,54 31,-38 c 63,-80 158,-156 260,-207 l 52,-26 -6,-43 C 4268,1645 4136,1244 4054,1095 3986,973 3841,753 3809,724 3796,712 3693,630 3580,541 3418,413 3362,364 3315,302 3249,217 3176,170 3111,170 c -54,0 -130,41 -183,98 -101,108 -240,349 -254,438 -11,74 5,96 115,158 53,30 123,73 155,95 l 60,40 29,-40 c 16,-22 31,-39 32,-37 2,2 -2,32 -7,68 -8,58 -4,266 8,330 6,37 -41,-64 -66,-141 l -21,-66 -82,-12 c -184,-29 -469,-30 -627,-3 l -45,7 -25,125 -25,125 -5,-255 c -6,-286 -4,-278 -93,-416 -76,-120 -84,-140 -90,-244 -9,-164 -29,-185 -172,-184 -101,1 -150,9 -345,61 -161,43 -243,81 -270,126 -26,43 -26,53 15,178 33,102 85,333 85,377 0,11 -22,53 -48,94 -158,239 -293,538 -356,794 -40,160 -50,247 -50,449 -1,219 11,293 74,462 109,289 264,521 458,687 260,221 518,338 894,404 l 108,19 -40,-46 c -21,-25 -102,-120 -180,-211 -168,-197 -228,-283 -320,-465 -83,-161 -115,-257 -107,-321 6,-60 54,-152 124,-244 90,-117 158,-224 183,-285 l 23,-55 -26,-78 c -14,-43 -29,-109 -33,-146 l -7,-68 74,-75 c 148,-150 237,-203 374,-224 63,-9 96,-9 155,1 77,13 78,13 430,198 175,91 324,145 452,163 l 87,12 30,96 c 46,143 62,232 68,372 7,148 -6,285 -46,499 -32,170 -57,359 -67,518 -4,56 -10,105 -14,107 -9,6 -26,-85 -41,-220 -15,-129 -6,-282 26,-475 32,-189 43,-421 26,-540 -13,-85 -64,-245 -83,-256 -6,-4 -46,-13 -90,-21 -132,-22 -272,-83 -528,-226 -195,-109 -199,-111 -320,-111 -146,-1 -192,19 -310,131 -49,46 -92,93 -95,103 -3,10 -1,49 5,86 12,82 101,267 238,499 131,222 136,231 125,220 -33,-33 -230,-274 -282,-345 -35,-47 -66,-86 -70,-87 -3,-1 -18,24 -33,55 -15,31 -68,111 -118,177 -104,139 -130,188 -130,249 0,57 15,97 94,255 84,168 120,220 269,389 67,76 192,219 278,318 190,218 368,392 429,422 27,13 109,31 205,47 178,28 417,74 425,82 5,5 -159,-2 -312,-13 -44,-3 -78,-1 -78,4 0,19 161,200 218,245 146,115 489,256 737,303 106,20 340,12 435,-15 z M 651,3379 c -22,-49 -41,-150 -41,-217 0,-69 -20,-128 -56,-171 l -35,-40 31,-60 c 29,-59 53,-81 84,-81 28,0 126,41 175,74 l 48,33 -30,-88 -30,-87 -57,-16 c -70,-20 -120,-20 -165,-2 -43,18 -58,43 -94,149 -16,47 -40,100 -53,117 -18,25 -23,44 -23,93 1,71 27,129 95,209 39,45 159,142 166,135 3,-2 -5,-24 -15,-48 z M 924,1470 c 44,-104 142,-290 200,-383 49,-79 54,-90 45,-119 -23,-84 -64,-118 -140,-118 -123,0 -358,170 -436,317 -31,58 -63,157 -63,196 0,12 54,75 129,151 94,96 132,142 141,171 7,22 15,44 18,49 3,5 22,-38 42,-95 20,-57 49,-133 64,-169 z m 3454,-13 c 60,-162 69,-208 76,-410 5,-144 10,-196 22,-220 12,-23 15,-49 12,-103 -5,-80 -24,-119 -64,-134 -52,-20 -498,-7 -558,16 -13,5 -7,16 31,58 66,73 182,253 250,387 35,68 84,193 123,310 36,108 67,195 70,192 2,-2 20,-45 38,-96 z"/>
    <path id="path8" d="m 4395,4151 c -111,-40 -200,-102 -231,-163 -22,-43 -34,-119 -25,-174 l 7,-49 22,70 c 23,75 80,172 128,217 16,15 60,47 99,72 75,50 75,54 0,27 z"/>
    <path id="path10" d="m 3285,4129 c -238,-26 -230,-24 -291,-81 -65,-61 -126,-174 -184,-343 -44,-130 -93,-295 -88,-301 2,-1 36,72 76,164 107,248 193,385 264,423 15,8 14,2 -7,-43 -20,-43 -25,-68 -24,-133 1,-44 4,-91 8,-105 6,-21 9,-16 20,33 16,73 68,176 125,248 41,52 50,58 118,78 40,12 109,35 153,51 74,26 77,29 40,28 -22,0 -116,-9 -210,-19 z"/>
    <path id="path12" d="m 6411,4074 c -36,-68 -146,-181 -228,-235 -82,-53 -153,-74 -224,-66 -27,3 -49,4 -49,2 0,-12 122,-36 166,-33 138,12 282,139 344,305 27,72 22,86 -9,27 z"/>
    <path id="path14" d="m 4825,3775 c -22,-7 -80,-22 -130,-34 -51,-12 -104,-31 -125,-46 -38,-27 -243,-265 -235,-273 3,-3 31,13 62,34 32,21 61,40 64,42 3,1 12,-17 18,-41 7,-24 23,-56 34,-71 l 22,-27 -3,44 c -3,35 1,50 17,66 41,41 105,36 135,-11 8,-14 -1,-29 -55,-85 -66,-68 -80,-88 -99,-139 -8,-21 7,-10 68,48 122,116 262,205 410,258 34,13 60,25 58,28 -5,4 -108,-12 -152,-24 -17,-5 -22,0 -27,23 -8,40 -47,94 -84,118 -18,11 -32,22 -33,25 0,3 20,18 45,33 35,23 71,53 53,46 -2,-1 -21,-7 -43,-14 z"/>
    <path id="path16" d="m 329,3563 c -133,-97 -196,-178 -225,-288 -16,-60 -19,-335 -4,-335 6,0 10,18 10,41 0,72 40,240 75,317 38,82 98,170 170,250 26,29 45,55 43,58 -3,2 -34,-17 -69,-43 z"/>
  </g>
</svg>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading our data from hdfs \n",
    "The data we just send have the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "\t\"metadata\": {\n",
    "\t\t\"hostname\": \"monit-amqsource-42bd3643dc.cern.ch\",\n",
    "\t\t\"partition\": \"9\",\n",
    "\t\t\"type_prefix\": \"raw\",\n",
    "\t\t\"kafka_timestamp\": 1583833262584,\n",
    "\t\t\"topic\": \"cms-training_raw_metric\",\n",
    "\t\t\"producer\": \"cms-training\",\n",
    "\t\t\"_id\": \"3c8955e8-8dad-41d1-a68f-3552056ecdb9\",\n",
    "\t\t\"type\": \"metric\",\n",
    "\t\t\"version\": \"001\",\n",
    "\t\t\"timestamp\": 1583833261994\n",
    "\t},\n",
    "\t\"data\": {\n",
    "\t\t\"id\": 3,\n",
    "\t\t\"country\": \"ID\",\n",
    "\t\t\"tier\": \"T3\",\n",
    "\t\t\"siteName\": \"T3_ID_afternoon\",\n",
    "\t\t\"requestedCores\": 4.23,\n",
    "\t\t\"requestedMB\": 501,\n",
    "\t\t\"usedMB\": 3102,\n",
    "\t\t\"training_username\": \"carizapo\",\n",
    "\t\t\"metadata\": {\n",
    "\t\t\t\"uuid\": \"3c8955e8-8dad-41d1-a68f-3552056ecdb9\"\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "```\n",
    "Note that our original data is included into the `data` property.\n",
    "\n",
    "So, the first thing we should do is to define the schema we'll use to read the data in spark. This step is optional but highly recommended, if we don't specify a schema, spark will try to infer the schema reading a sample of the data (even worse, the sampling ratio is 1 by default).\n",
    "\n",
    "In the schema, we only need to include the fields we will use in the current application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, DoubleType\n",
    "_schema = StructType([\n",
    "    StructField(\"metadata\", StructType([StructField(\"timestamp\",LongType(), nullable=False)])),\n",
    "    StructField(\"data\", StructType([\n",
    "        StructField(\"country\", StringType(), nullable=True),\n",
    "        StructField(\"tier\", StringType(), nullable=True),\n",
    "        StructField(\"siteName\", StringType(), nullable=True),\n",
    "        StructField(\"requestedMB\", DoubleType(), nullable=True),\n",
    "        StructField(\"usedMB\", DoubleType(), nullable=True),\n",
    "        StructField(\"training_username\", StringType(), nullable=True),\n",
    "    ])),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read the json files, in this case we are only interested in the ones we just created, but the path can use glob expressions, or a list, to select multiple directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.now()\n",
    "base = \"/project/monitoring/archive/cms-training/raw/metric\"\n",
    "training_df = spark.read.json(f\"{base}/{today.strftime('%Y/%m/%d')}{{.tmp,}}\", schema=_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- timestamp: long (nullable = true)\n",
      " |-- data: struct (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- tier: string (nullable = true)\n",
      " |    |-- siteName: string (nullable = true)\n",
      " |    |-- requestedMB: double (nullable = true)\n",
      " |    |-- usedMB: double (nullable = true)\n",
      " |    |-- training_username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While multiple users can send data to the same datasource, we are only interested in data created by the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = (training_df.where( f\"data.training_username == '{os.getenv('USER')}'\")\n",
    "                          .select(\"metadata.timestamp\", \"data.*\")\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to check the memory efficiency by country/tier/sitename so we can create  a dataframe grouping by those attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (training_df.groupBy([\"country\", \"tier\", \"siteName\"])\n",
    "                         .agg({\"requestedMB\":\"sum\", \"usedMB\":\"sum\"})\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the memoryEff column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (grouped_df.withColumnRenamed(\"sum(usedMB)\",\"used\")\n",
    "                        .withColumnRenamed(\"sum(requestedMB)\",\"requested\")\n",
    "                        .withColumn(\"MemoryEff\", col(\"used\")/col(\"requested\"))\n",
    "                        .cache()\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the memory limits are not enforced, we can look at the sites that get more memory used than requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>tier</th>\n",
       "      <th>siteName</th>\n",
       "      <th>requested</th>\n",
       "      <th>used</th>\n",
       "      <th>MemoryEff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT</td>\n",
       "      <td>T0</td>\n",
       "      <td>T0_PT_lapses</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FI</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2_FI_satanic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2624.0</td>\n",
       "      <td>656.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PL</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1_PL_lushest</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3468.0</td>\n",
       "      <td>247.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_CN_interlude</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>186.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UA</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1_UA_perverted</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>146.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RU</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_RU_chaff</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>105.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AR</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_AR_keened</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>105.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PG</td>\n",
       "      <td>T0</td>\n",
       "      <td>T0_PG_steering</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>102.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AF</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_AF_stork's</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3607.0</td>\n",
       "      <td>94.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GR</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_GR_polishes</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>91.740741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country tier         siteName  requested    used   MemoryEff\n",
       "0      PT   T0     T0_PT_lapses        0.0  2209.0         NaN\n",
       "1      FI   T2    T2_FI_satanic        4.0  2624.0  656.000000\n",
       "2      PL   T1    T1_PL_lushest       14.0  3468.0  247.714286\n",
       "3      CN   T3  T3_CN_interlude       10.0  1869.0  186.900000\n",
       "4      UA   T1  T1_UA_perverted        9.0  1322.0  146.888889\n",
       "5      RU   T3      T3_RU_chaff       14.0  1480.0  105.714286\n",
       "6      AR   T3     T3_AR_keened       29.0  3052.0  105.241379\n",
       "7      PG   T0   T0_PG_steering       17.0  1748.0  102.823529\n",
       "8      AF   T3    T3_AF_stork's       38.0  3607.0   94.921053\n",
       "9      GR   T3   T3_GR_polishes       27.0  2477.0   91.740741"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overuse_df = grouped_df.orderBy(grouped_df.MemoryEff.desc_nulls_first()).limit(10).toPandas()\n",
    "display(overuse_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can get the ones that get more memory requested than used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>tier</th>\n",
       "      <th>siteName</th>\n",
       "      <th>requested</th>\n",
       "      <th>used</th>\n",
       "      <th>MemoryEff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PH</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_PH_slant's</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1_ID_homemade</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_PT_compelled</td>\n",
       "      <td>5985.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.003008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NG</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2_NG_pagan's</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.003513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_PT_priest</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CN</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_CN_virtue's</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.011765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PH</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_PH_longing</td>\n",
       "      <td>532.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.024436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CA</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_CA_fired</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.033144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CN</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_CN_respites</td>\n",
       "      <td>889.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.033746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CA</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3_CA_slashed</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.035786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country tier         siteName  requested  used  MemoryEff\n",
       "0      PH   T3    T3_PH_slant's     1902.0   0.0   0.000000\n",
       "1      ID   T1   T1_ID_homemade     1742.0   2.0   0.001148\n",
       "2      PT   T3  T3_PT_compelled     5985.0  18.0   0.003008\n",
       "3      NG   T2    T2_NG_pagan's     1708.0   6.0   0.003513\n",
       "4      PT   T3     T3_PT_priest     1344.0  14.0   0.010417\n",
       "5      CN   T3   T3_CN_virtue's     1105.0  13.0   0.011765\n",
       "6      PH   T3    T3_PH_longing      532.0  13.0   0.024436\n",
       "7      CA   T3      T3_CA_fired     1056.0  35.0   0.033144\n",
       "8      CN   T3   T3_CN_respites      889.0  30.0   0.033746\n",
       "9      CA   T3    T3_CA_slashed     1984.0  71.0   0.035786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overrequest_df = grouped_df.orderBy(grouped_df.MemoryEff.asc_nulls_last()).limit(10).toPandas()\n",
    "display(overrequest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": []
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
